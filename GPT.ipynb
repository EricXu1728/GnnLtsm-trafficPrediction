{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GCN\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Step 1: Load your data into a torch_geometric.data.Data object\n",
    "x = torch.randn(100, 16) # node feature matrix\n",
    "edge_index = torch.randint(0, 100, (2, 200)) # edge indices\n",
    "y = torch.randint(0, 2, (100,)) # target labels\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# Step 2: Create a GCN model instance and set its hyperparameters\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(16, 32) # GCN layer with 16 input features and 32 output features\n",
    "        self.conv2 = GCNConv(32, 2) # GCN layer with 32 input features and 2 output features\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# Step 3: Define the loss function you want to use for training\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Step 4: Initialize an optimizer and set its hyperparameters\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "# Step 5: Split your data into training and validation sets\n",
    "train_loader = DataLoader(data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Step 6: Create a training loop and backpropagate the gradients\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Step 7: Evaluate the performance of the model on the validation set\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index)\n",
    "            loss += criterion(out, data.y).item()\n",
    "            _, predicted = torch.max(out.data, 1)\n",
    "            total += data.y.size(\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
