{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Frank\\AppData\\Local\\Temp\\ipykernel_6076\\2626032721.py:4: DtypeWarning: Columns (5,6,7,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('mot_labels.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id\n",
      "0        89537.0\n",
      "1        89538.0\n",
      "2        89539.0\n",
      "3        89540.0\n",
      "4        89541.0\n",
      "...          ...\n",
      "2890739  70589.0\n",
      "2890768  70590.0\n",
      "2890792  70591.0\n",
      "2890813  70592.0\n",
      "2890817  70593.0\n",
      "\n",
      "[112820 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('mot_labels.csv')\n",
    "df['category'] = df['category'].map({'car': 1, 'pedestrian': 0, 3: 3}).fillna(3).astype(int)\n",
    "\n",
    "ids = df[[\"id\"]].drop_duplicates()\n",
    "\n",
    "print(ids)\n",
    "\n",
    "#This code gets a list of all unique ID's in the dataset and stores it in ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dimentions of the video\n",
    "min_value = 0\n",
    "max_xValue = 1280\n",
    "max_yValue = 720\n",
    "#Normalization is when a value is mapped between 0 and 1\n",
    "#This maps the coordinants of the screen between 1 and 0\n",
    "def normalize(df, min, maxX, maxY):\n",
    "  #print(df['box2d.x2'])\n",
    "  \n",
    "  df['box2d.x1'] = (df['box2d.x1'] - min) / (maxX - min)\n",
    "  df['box2d.x2'] = (df['box2d.x2'] - min) / (maxX - min)\n",
    "  df['box2d.y1'] = (df['box2d.y1'] - min) / (maxY - min)\n",
    "  df['box2d.y2'] = (df['box2d.y2'] - min) / (maxY - min)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87944.0\n"
     ]
    }
   ],
   "source": [
    "#Gets the Object id of the object that appears most in the video, meaning that the object will have the longest path\n",
    "counts = df['id'].value_counts()\n",
    "\n",
    "# get the value that appears the most number of times\n",
    "most_common_value = counts.idxmax()\n",
    "\n",
    "print(most_common_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "#minimum length of a desired path\n",
    "minLength = 150\n",
    "#The maximum number of paths generated\n",
    "samples = 100 #turned down for this demonstration. Was previously 5000\n",
    "\n",
    "list = []\n",
    "i = 0\n",
    "LENGTH = 0\n",
    "\n",
    "for ind in ids.index:\n",
    "  \n",
    "  #break out of loop if we hit maximum samples\n",
    "  if i>samples:\n",
    "    break\n",
    "  \n",
    "  #gets the path with the specific ID\n",
    "  value = ids['id'][ind]\n",
    "  path = df.loc[df['id'] == value] \n",
    "\n",
    "  #skip if the length of the path is too small\n",
    "  if len(path)<minLength:\n",
    "    continue\n",
    "  \n",
    "  #Gets the 'category','box2d.x1','box2d.x2','box2d.y1','box2d.y2', which is the important data\n",
    "  path = path[['category','box2d.x1','box2d.x2','box2d.y1','box2d.y2']]\n",
    "  path['box2d.x1']= path['box2d.x1'].astype(np.float64)\n",
    "  path['box2d.x2']= path['box2d.x1'].astype(np.float64)\n",
    "  path['box2d.y1']= path['box2d.x1'].astype(np.float64)\n",
    "  path['box2d.y2']= path['box2d.x1'].astype(np.float64)\n",
    "  \n",
    "  #normalizes this data\n",
    "  print(i)\n",
    "  path = normalize(path, min_value, max_xValue, max_yValue)\n",
    "  \n",
    "  #appends it to list\n",
    "  list.append(path)\n",
    "  i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "       category  box2d.x1  box2d.x2  box2d.y1  box2d.y2\n",
      "9171          1  0.227488  0.227488  0.404423  0.404423\n",
      "9176          1  0.227850  0.227850  0.405066  0.405066\n",
      "9181          1  0.227773  0.227773  0.404929  0.404929\n",
      "9187          1  0.228546  0.228546  0.406304  0.406304\n",
      "9193          1  0.227722  0.227722  0.404840  0.404840\n",
      "...         ...       ...       ...       ...       ...\n",
      "10342         1  0.235769  0.235769  0.419144  0.419144\n",
      "10352         1  0.235928  0.235928  0.419428  0.419428\n",
      "10361         1  0.236247  0.236247  0.419995  0.419995\n",
      "10368         1  0.234972  0.234972  0.417727  0.417727\n",
      "10375         1  0.233443  0.233443  0.415010  0.415010\n",
      "\n",
      "[202 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#list contains a list of individual object paths\n",
    "#Prints the path of the first object\n",
    "print(\"Sample\")\n",
    "print(list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each sequence we give the LTSM a small window of it with length of lookback\n",
    "#Given a sequence of [1, 2, 3, 4, 5, 6] and a lookback of 3, the method would return:\n",
    "\"\"\"\n",
    "[[1, 2, 3],\n",
    "[2, 3, 4],\n",
    "[3, 4, 5],\n",
    "[3, 5, 6]]\n",
    "\"\"\"\n",
    "#We do this because we want to give the ltsm [1, 2, 3] to predict 4, then [2, 3, 4] to predict 5 and so on\n",
    "def split_data(paths, lookback):\n",
    "    data_raw = paths.to_numpy() # convert to numpy array\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    # create all possible sequences of length lookback\n",
    "    for index in range(len(data_raw) - lookback): \n",
    "        data.append(data_raw[index: index + lookback])\n",
    "    \n",
    "    data = np.array(data)\n",
    "    test_set_size = int(np.round(0.2*data.shape[0]))\n",
    "    train_set_size = data.shape[0] - (test_set_size)\n",
    "\n",
    "    \n",
    "    x_train = data[:train_set_size,:-1,:]\n",
    "    y_train = data[:train_set_size,-1,:]\n",
    "    \n",
    "    x_test = data[train_set_size:,:-1]\n",
    "    y_test = data[train_set_size:,-1,:]\n",
    "    \n",
    "    return [x_train, y_train, x_test, y_test]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "lookback = 10  # choose sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize LTSM class\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 5\n",
    "hidden_dim = 32\n",
    "num_layers = 2\n",
    "output_dim = 5\n",
    "num_epochs = 150 #turned down for this demonstration. Was 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data  0 MSE:  0.0002041455009020865\n",
      "Data  1 MSE:  7.186168659245595e-06\n",
      "Data  2 MSE:  8.661724677949678e-06\n",
      "Data  3 MSE:  4.687935415859101e-06\n",
      "Data  4 MSE:  6.113641575211659e-06\n",
      "Data  5 MSE:  1.0578409273875877e-05\n",
      "Data  6 MSE:  1.1384614481357858e-05\n",
      "Data  7 MSE:  5.2960945140512194e-06\n",
      "Data  8 MSE:  7.787951290083583e-06\n",
      "Data  9 MSE:  2.1761268726550043e-05\n",
      "Data  10 MSE:  0.0010517039336264133\n",
      "Data  11 MSE:  0.0003122840716969222\n",
      "Data  12 MSE:  0.00022397132124751806\n",
      "Data  13 MSE:  6.762067641830072e-05\n",
      "Data  14 MSE:  0.0004992866306565702\n",
      "Data  15 MSE:  0.00020765162480529398\n",
      "Data  16 MSE:  2.0578776457114145e-05\n",
      "Data  17 MSE:  1.0877552995225415e-05\n",
      "Data  18 MSE:  2.1493595340871252e-05\n",
      "Data  19 MSE:  1.7314569049631245e-05\n",
      "Data  20 MSE:  1.5929665096336976e-05\n",
      "Data  21 MSE:  1.739465369610116e-05\n",
      "Data  22 MSE:  1.1309490218991414e-05\n",
      "Data  23 MSE:  3.306853977846913e-05\n",
      "Data  24 MSE:  1.6327032426488586e-05\n",
      "Data  25 MSE:  0.004059011582285166\n",
      "Data  26 MSE:  0.00013603366096504033\n",
      "Data  27 MSE:  2.3855947802076116e-05\n",
      "Data  28 MSE:  4.085539694642648e-05\n",
      "Data  29 MSE:  3.121873669442721e-05\n",
      "Data  30 MSE:  0.0006002475274726748\n",
      "Data  31 MSE:  5.3505023061006796e-06\n",
      "Data  32 MSE:  0.0001282201410504058\n",
      "Data  33 MSE:  3.1317135551489628e-09\n",
      "Data  34 MSE:  4.750450170831755e-05\n",
      "Data  35 MSE:  2.7083315217169002e-05\n",
      "Data  36 MSE:  9.943264012690634e-05\n",
      "Data  37 MSE:  2.5310768251074478e-05\n",
      "Data  38 MSE:  3.4257453080499545e-05\n",
      "Data  39 MSE:  1.5161114788497798e-05\n",
      "Data  40 MSE:  4.371632712718565e-06\n",
      "Data  41 MSE:  6.286332791205496e-05\n",
      "Data  42 MSE:  2.8028998713125475e-05\n",
      "Data  43 MSE:  7.078938324411865e-06\n",
      "Data  44 MSE:  0.0014507538871839643\n",
      "Data  45 MSE:  0.00048449108726345\n",
      "Data  46 MSE:  9.352930646855384e-05\n",
      "Data  47 MSE:  9.67354208114557e-05\n",
      "Data  48 MSE:  0.0005341178621165454\n",
      "Data  49 MSE:  2.9661265216418542e-05\n",
      "Data  50 MSE:  1.4434659533435479e-05\n",
      "Data  51 MSE:  1.2493354915932287e-05\n",
      "Data  52 MSE:  5.416973726823926e-05\n",
      "Data  53 MSE:  6.547637440235121e-06\n",
      "Data  54 MSE:  3.0798021271039033e-06\n",
      "Data  55 MSE:  2.5443728191021364e-06\n",
      "Data  56 MSE:  0.0009208763367496431\n",
      "Data  57 MSE:  0.006159050855785608\n",
      "Data  58 MSE:  0.0016666377196088433\n",
      "Data  59 MSE:  0.0018814059440046549\n",
      "Data  60 MSE:  2.9731952963629737e-05\n",
      "Data  61 MSE:  9.218644845532253e-05\n",
      "Data  62 MSE:  0.0002635370765347034\n",
      "Data  63 MSE:  8.121065184241161e-05\n",
      "Data  64 MSE:  3.953547638957389e-05\n",
      "Data  65 MSE:  0.0007448415271937847\n",
      "Data  66 MSE:  0.0007830794202163815\n",
      "Data  67 MSE:  0.00015436959802173078\n",
      "Data  68 MSE:  6.493440741905943e-05\n",
      "Data  69 MSE:  2.3614476958755404e-05\n",
      "Data  70 MSE:  6.654159733443521e-06\n",
      "Data  71 MSE:  8.172162779374048e-05\n",
      "Data  72 MSE:  6.1302898757276125e-06\n",
      "Data  73 MSE:  1.5256066035362892e-05\n",
      "Data  74 MSE:  3.5940711313742213e-06\n",
      "Data  75 MSE:  4.812839051737683e-07\n",
      "Data  76 MSE:  7.544045729446225e-06\n",
      "Data  77 MSE:  1.0803145414683968e-05\n",
      "Data  78 MSE:  4.1937138917091943e-07\n",
      "Data  79 MSE:  3.607884718803689e-05\n",
      "Data  80 MSE:  2.5238203306798823e-05\n",
      "Data  81 MSE:  1.3465858501149341e-05\n",
      "Data  82 MSE:  0.004570598714053631\n",
      "Data  83 MSE:  0.0008043179986998439\n",
      "Data  84 MSE:  0.0005730842822231352\n",
      "Data  85 MSE:  2.2849066226626746e-05\n",
      "Data  86 MSE:  0.00031154247699305415\n",
      "Data  87 MSE:  1.234148112416733e-05\n",
      "Data  88 MSE:  4.835992876905948e-05\n",
      "Data  89 MSE:  8.05042072897777e-05\n",
      "Data  90 MSE:  3.544987805526034e-07\n",
      "Data  91 MSE:  1.5037922821647953e-05\n",
      "Data  92 MSE:  1.1161491784150712e-06\n",
      "Data  93 MSE:  8.19622800918296e-05\n",
      "Data  94 MSE:  2.2611463919020025e-06\n",
      "Data  95 MSE:  5.515401880984427e-06\n",
      "Data  96 MSE:  3.573929461708758e-06\n",
      "Data  97 MSE:  1.697007792245131e-05\n",
      "Data  98 MSE:  3.0944167519919574e-05\n",
      "Data  99 MSE:  0.0031819299329072237\n",
      "Data  100 MSE:  0.0012494188267737627\n",
      "Training time: 206.4797465801239\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "start_time = time.time()\n",
    "lstm = []\n",
    "\n",
    "#Idealy, we should only train it on one sequence, but due to the limited data, we will train it accross multiple sequences\n",
    "for x in range(len(list)):\n",
    "    \n",
    "    dataf = list[x]\n",
    "    \n",
    "    if dataf.empty or dataf.shape[0]<= lookback:\n",
    "        continue\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = split_data(list[x], lookback)\n",
    "\n",
    "    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n",
    "    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n",
    "    y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor)\n",
    "    y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor)\n",
    "    \n",
    "    for t in range(num_epochs):\n",
    "        y_train_pred = model(x_train)\n",
    "\n",
    "        loss = criterion(y_train_pred, y_train_lstm)\n",
    "        #print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "        hist[t] = loss.item()\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    print(\"Data \", x, \"MSE: \", loss.item())\n",
    "    \n",
    "training_time = time.time()-start_time\n",
    "print(\"Training time: {}\".format(training_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0000, 0.1038, 0.1038, 0.1845, 0.1845],\n",
      "         [1.0000, 0.1136, 0.1136, 0.2020, 0.2020],\n",
      "         [1.0000, 0.1103, 0.1103, 0.1960, 0.1960],\n",
      "         ...,\n",
      "         [1.0000, 0.1295, 0.1295, 0.2301, 0.2301],\n",
      "         [1.0000, 0.1393, 0.1393, 0.2477, 0.2477],\n",
      "         [1.0000, 0.1413, 0.1413, 0.2512, 0.2512]],\n",
      "\n",
      "        [[1.0000, 0.1136, 0.1136, 0.2020, 0.2020],\n",
      "         [1.0000, 0.1103, 0.1103, 0.1960, 0.1960],\n",
      "         [1.0000, 0.1235, 0.1235, 0.2196, 0.2196],\n",
      "         ...,\n",
      "         [1.0000, 0.1393, 0.1393, 0.2477, 0.2477],\n",
      "         [1.0000, 0.1413, 0.1413, 0.2512, 0.2512],\n",
      "         [1.0000, 0.1449, 0.1449, 0.2576, 0.2576]],\n",
      "\n",
      "        [[1.0000, 0.1103, 0.1103, 0.1960, 0.1960],\n",
      "         [1.0000, 0.1235, 0.1235, 0.2196, 0.2196],\n",
      "         [1.0000, 0.1235, 0.1235, 0.2196, 0.2196],\n",
      "         ...,\n",
      "         [1.0000, 0.1413, 0.1413, 0.2512, 0.2512],\n",
      "         [1.0000, 0.1449, 0.1449, 0.2576, 0.2576],\n",
      "         [1.0000, 0.1449, 0.1449, 0.2576, 0.2576]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.1065, 0.1065, 0.1893, 0.1893],\n",
      "         [1.0000, 0.0876, 0.0876, 0.1557, 0.1557],\n",
      "         [1.0000, 0.0468, 0.0468, 0.0832, 0.0832],\n",
      "         ...,\n",
      "         [1.0000, 0.0132, 0.0132, 0.0234, 0.0234],\n",
      "         [1.0000, 0.0095, 0.0095, 0.0168, 0.0168],\n",
      "         [1.0000, 0.0070, 0.0070, 0.0125, 0.0125]],\n",
      "\n",
      "        [[1.0000, 0.0876, 0.0876, 0.1557, 0.1557],\n",
      "         [1.0000, 0.0468, 0.0468, 0.0832, 0.0832],\n",
      "         [1.0000, 0.0544, 0.0544, 0.0968, 0.0968],\n",
      "         ...,\n",
      "         [1.0000, 0.0095, 0.0095, 0.0168, 0.0168],\n",
      "         [1.0000, 0.0070, 0.0070, 0.0125, 0.0125],\n",
      "         [1.0000, 0.0063, 0.0063, 0.0112, 0.0112]],\n",
      "\n",
      "        [[1.0000, 0.0468, 0.0468, 0.0832, 0.0832],\n",
      "         [1.0000, 0.0544, 0.0544, 0.0968, 0.0968],\n",
      "         [1.0000, 0.0313, 0.0313, 0.0557, 0.0557],\n",
      "         ...,\n",
      "         [1.0000, 0.0070, 0.0070, 0.0125, 0.0125],\n",
      "         [1.0000, 0.0063, 0.0063, 0.0112, 0.0112],\n",
      "         [1.0000, 0.0079, 0.0079, 0.0140, 0.0140]]])\n",
      "tensor([[1.0168, 0.1429, 0.1433, 0.2548, 0.2544],\n",
      "        [1.0160, 0.1445, 0.1450, 0.2578, 0.2574],\n",
      "        [1.0160, 0.1446, 0.1451, 0.2579, 0.2575],\n",
      "        [1.0163, 0.1439, 0.1444, 0.2567, 0.2563],\n",
      "        [1.0163, 0.1439, 0.1443, 0.2566, 0.2562],\n",
      "        [1.0164, 0.1437, 0.1442, 0.2564, 0.2560],\n",
      "        [1.0164, 0.1438, 0.1443, 0.2565, 0.2561],\n",
      "        [1.0164, 0.1438, 0.1442, 0.2564, 0.2561],\n",
      "        [1.0168, 0.1428, 0.1433, 0.2547, 0.2544],\n",
      "        [1.0173, 0.1416, 0.1420, 0.2525, 0.2521],\n",
      "        [1.0168, 0.1429, 0.1434, 0.2549, 0.2545],\n",
      "        [1.0151, 0.1466, 0.1471, 0.2614, 0.2611],\n",
      "        [1.0122, 0.1534, 0.1538, 0.2733, 0.2730],\n",
      "        [1.0089, 0.1610, 0.1613, 0.2867, 0.2864],\n",
      "        [1.0046, 0.1710, 0.1712, 0.3043, 0.3041],\n",
      "        [1.0015, 0.1782, 0.1783, 0.3169, 0.3168],\n",
      "        [0.9941, 0.1952, 0.1951, 0.3466, 0.3467],\n",
      "        [0.9948, 0.1936, 0.1936, 0.3439, 0.3439],\n",
      "        [0.9953, 0.1925, 0.1924, 0.3419, 0.3420],\n",
      "        [1.0087, 0.1615, 0.1618, 0.2875, 0.2873],\n",
      "        [1.0158, 0.1451, 0.1455, 0.2587, 0.2583],\n",
      "        [1.0194, 0.1368, 0.1373, 0.2442, 0.2438],\n",
      "        [1.0221, 0.1306, 0.1312, 0.2334, 0.2329],\n",
      "        [1.0238, 0.1266, 0.1272, 0.2262, 0.2257],\n",
      "        [1.0255, 0.1226, 0.1233, 0.2193, 0.2187],\n",
      "        [1.0276, 0.1179, 0.1186, 0.2110, 0.2103],\n",
      "        [1.0273, 0.1185, 0.1192, 0.2121, 0.2114],\n",
      "        [1.0281, 0.1166, 0.1173, 0.2088, 0.2081],\n",
      "        [1.0279, 0.1171, 0.1179, 0.2097, 0.2090],\n",
      "        [1.0285, 0.1158, 0.1165, 0.2072, 0.2066],\n",
      "        [1.0285, 0.1158, 0.1165, 0.2073, 0.2066],\n",
      "        [1.0285, 0.1156, 0.1164, 0.2070, 0.2063],\n",
      "        [1.0285, 0.1157, 0.1164, 0.2071, 0.2064],\n",
      "        [1.0285, 0.1157, 0.1164, 0.2071, 0.2065]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(x_test)\n",
    "\n",
    "print(model(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unNormalize(df, min, maxX, maxY):\n",
    "    if(df.ndim ==3):\n",
    "        for i in range(df.shape[0]):\n",
    "        \n",
    "        \n",
    "            #for j in range(df.shape[1]):\n",
    "            df[i][1] = (df[i][1]  + min) * (maxX - min)\n",
    "            df[i][2] = (df[i][2]  + min) * (maxX - min)\n",
    "            df[i][3] = (df[i][3]  + min) * (maxY - min)\n",
    "            df[i][4] = (df[i][4]  + min) * (maxY - min)\n",
    "        \n",
    "    if(df.ndim ==2):\n",
    "        for i in range(df.shape[0]):\n",
    "            print(\"wow\")\n",
    "            \n",
    "            what  = df[i][3]\n",
    "            print(what)\n",
    "            print((what  + min) * (maxY - min))\n",
    "            df[i][1] = (df[i][1]  + min) * (maxX - min)\n",
    "            df[i][2] = (df[i][2]  + min) * (maxX - min)\n",
    "            df[i][3] = (what  + min) * (maxY - min)\n",
    "            df[i][4] = (df[i][4]  + min) * (maxY - min)\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test\n",
      "tensor([[[1.0000, 0.1038, 0.1038, 0.1845, 0.1845],\n",
      "         [1.0000, 0.1136, 0.1136, 0.2020, 0.2020],\n",
      "         [1.0000, 0.1103, 0.1103, 0.1960, 0.1960],\n",
      "         ...,\n",
      "         [1.0000, 0.1295, 0.1295, 0.2301, 0.2301],\n",
      "         [1.0000, 0.1393, 0.1393, 0.2477, 0.2477],\n",
      "         [1.0000, 0.1413, 0.1413, 0.2512, 0.2512]],\n",
      "\n",
      "        [[1.0000, 0.1136, 0.1136, 0.2020, 0.2020],\n",
      "         [1.0000, 0.1103, 0.1103, 0.1960, 0.1960],\n",
      "         [1.0000, 0.1235, 0.1235, 0.2196, 0.2196],\n",
      "         ...,\n",
      "         [1.0000, 0.1393, 0.1393, 0.2477, 0.2477],\n",
      "         [1.0000, 0.1413, 0.1413, 0.2512, 0.2512],\n",
      "         [1.0000, 0.1449, 0.1449, 0.2576, 0.2576]],\n",
      "\n",
      "        [[1.0000, 0.1103, 0.1103, 0.1960, 0.1960],\n",
      "         [1.0000, 0.1235, 0.1235, 0.2196, 0.2196],\n",
      "         [1.0000, 0.1235, 0.1235, 0.2196, 0.2196],\n",
      "         ...,\n",
      "         [1.0000, 0.1413, 0.1413, 0.2512, 0.2512],\n",
      "         [1.0000, 0.1449, 0.1449, 0.2576, 0.2576],\n",
      "         [1.0000, 0.1449, 0.1449, 0.2576, 0.2576]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1.0000, 0.1065, 0.1065, 0.1893, 0.1893],\n",
      "         [1.0000, 0.0876, 0.0876, 0.1557, 0.1557],\n",
      "         [1.0000, 0.0468, 0.0468, 0.0832, 0.0832],\n",
      "         ...,\n",
      "         [1.0000, 0.0132, 0.0132, 0.0234, 0.0234],\n",
      "         [1.0000, 0.0095, 0.0095, 0.0168, 0.0168],\n",
      "         [1.0000, 0.0070, 0.0070, 0.0125, 0.0125]],\n",
      "\n",
      "        [[1.0000, 0.0876, 0.0876, 0.1557, 0.1557],\n",
      "         [1.0000, 0.0468, 0.0468, 0.0832, 0.0832],\n",
      "         [1.0000, 0.0544, 0.0544, 0.0968, 0.0968],\n",
      "         ...,\n",
      "         [1.0000, 0.0095, 0.0095, 0.0168, 0.0168],\n",
      "         [1.0000, 0.0070, 0.0070, 0.0125, 0.0125],\n",
      "         [1.0000, 0.0063, 0.0063, 0.0112, 0.0112]],\n",
      "\n",
      "        [[1.0000, 0.0468, 0.0468, 0.0832, 0.0832],\n",
      "         [1.0000, 0.0544, 0.0544, 0.0968, 0.0968],\n",
      "         [1.0000, 0.0313, 0.0313, 0.0557, 0.0557],\n",
      "         ...,\n",
      "         [1.0000, 0.0070, 0.0070, 0.0125, 0.0125],\n",
      "         [1.0000, 0.0063, 0.0063, 0.0112, 0.0112],\n",
      "         [1.0000, 0.0079, 0.0079, 0.0140, 0.0140]]])\n",
      "prediction:\n",
      "tensor([[1.0136, 0.1502, 0.1506, 0.2678, 0.2674],\n",
      "        [1.0126, 0.1524, 0.1528, 0.2716, 0.2713],\n",
      "        [1.0138, 0.1498, 0.1502, 0.2671, 0.2668],\n",
      "        [1.0143, 0.1486, 0.1490, 0.2649, 0.2645],\n",
      "        [1.0149, 0.1472, 0.1477, 0.2625, 0.2622],\n",
      "        [1.0149, 0.1472, 0.1476, 0.2624, 0.2620],\n",
      "        [1.0149, 0.1472, 0.1476, 0.2624, 0.2620],\n",
      "        [1.0150, 0.1470, 0.1475, 0.2622, 0.2618],\n",
      "        [1.0154, 0.1460, 0.1464, 0.2603, 0.2599],\n",
      "        [1.0161, 0.1445, 0.1450, 0.2578, 0.2574],\n",
      "        [1.0154, 0.1461, 0.1465, 0.2604, 0.2601],\n",
      "        [1.0133, 0.1509, 0.1513, 0.2690, 0.2687],\n",
      "        [1.0097, 0.1591, 0.1594, 0.2833, 0.2831],\n",
      "        [1.0067, 0.1661, 0.1663, 0.2955, 0.2953],\n",
      "        [1.0037, 0.1730, 0.1731, 0.3076, 0.3075],\n",
      "        [1.0037, 0.1731, 0.1733, 0.3079, 0.3078],\n",
      "        [1.0163, 0.1441, 0.1445, 0.2571, 0.2567],\n",
      "        [1.0169, 0.1427, 0.1431, 0.2546, 0.2541],\n",
      "        [1.0173, 0.1418, 0.1423, 0.2531, 0.2527],\n",
      "        [1.0222, 0.1305, 0.1310, 0.2332, 0.2326],\n",
      "        [1.0237, 0.1270, 0.1275, 0.2270, 0.2264],\n",
      "        [1.0247, 0.1248, 0.1254, 0.2231, 0.2225],\n",
      "        [1.0253, 0.1234, 0.1240, 0.2207, 0.2201],\n",
      "        [1.0258, 0.1222, 0.1228, 0.2186, 0.2180],\n",
      "        [1.0246, 0.1248, 0.1254, 0.2231, 0.2226],\n",
      "        [1.0269, 0.1195, 0.1201, 0.2137, 0.2131],\n",
      "        [1.0267, 0.1201, 0.1207, 0.2148, 0.2142],\n",
      "        [1.0275, 0.1180, 0.1187, 0.2113, 0.2106],\n",
      "        [1.0273, 0.1186, 0.1193, 0.2123, 0.2116],\n",
      "        [1.0279, 0.1170, 0.1177, 0.2095, 0.2088],\n",
      "        [1.0280, 0.1168, 0.1175, 0.2091, 0.2084],\n",
      "        [1.0281, 0.1167, 0.1174, 0.2088, 0.2082],\n",
      "        [1.0281, 0.1166, 0.1173, 0.2087, 0.2081],\n",
      "        [1.0281, 0.1166, 0.1173, 0.2088, 0.2081]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#We see an example of a prediction it would give\n",
    "print(\"x_test\")\n",
    "print(x_test)\n",
    "#unNorm = unNormalize(x_test,  min_value, max_xValue, max_yValue)\n",
    "\n",
    "#print(\"Unnormalized test\")\n",
    "#print(unNorm)\n",
    "\n",
    "prediction = model(x_test)\n",
    "print(\"prediction:\")\n",
    "print(prediction)\n",
    "\n",
    "#unNormPred = unNormalize(prediction,  min_value, max_xValue, max_yValue)\n",
    "\n",
    "#print(unNormPred)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
